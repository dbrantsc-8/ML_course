{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import implementations\n",
    "importlib.reload(implementations)\n",
    "from helpers import load_csv_data\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, train_ids, test_ids = load_csv_data('./data/dataset/dataset', sub_sample = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(x_train, y_train, lim_nans, lim_corr_features, lim_corr_target):\n",
    "\n",
    "    # Kept fatures\n",
    "    kept_features = np.array(range(x_train.shape[1]))\n",
    "    # Remove columns with more than lim_nans of Nans\n",
    "    percentages = np.sum(np.isnan(x_train), axis = 0) / x_train.shape[0]\n",
    "    x_tr = x_train[:, percentages < lim_nans]\n",
    "    kept_features = kept_features[percentages < lim_nans]\n",
    "\n",
    "    # Remove datapoints (rows) with one or multiple Nans\n",
    "    keep_idxs = (np.sum(np.isnan(x_tr), axis = 1)) == 0\n",
    "    x_tr = x_tr[keep_idxs, :]\n",
    "    y_tr = y_train[keep_idxs] \n",
    "\n",
    "    # Remove features with 0 variance\n",
    "    var = np.var(x_tr, axis = 0)\n",
    "    x_tr = x_tr[:, var != 0]\n",
    "    kept_features = kept_features[var != 0]\n",
    "\n",
    "    # Only keep 1 feature among highly correlated features\n",
    "    corr_tri = np.triu(np.abs(np.corrcoef(x_tr, rowvar = False)), k = 1) # upper triangular correlation matrix (diagonal zeroed as well)\n",
    "    max_corr = np.max(corr_tri, axis = 0)\n",
    "    x_tr = x_tr[:, max_corr < lim_corr_features]\n",
    "    kept_features = kept_features[max_corr < lim_corr_features]\n",
    "\n",
    "    # Remove features that have very low correlation with target value\n",
    "    corr_mat = np.abs(np.corrcoef(np.c_[y_tr, x_tr], rowvar = False))\n",
    "    x_tr = x_tr[:, corr_mat[0, 1:] > lim_corr_target] # first row of correlation matrix indicates correlation with target value vector y\n",
    "    kept_features = kept_features[corr_mat[0, 1:] > lim_corr_target]\n",
    "\n",
    "    # Standardise data along axis 0\n",
    "    centered_data = x_tr - np.mean(x_tr, axis = 0)\n",
    "    x_tr = centered_data / np.std(centered_data, axis = 0)\n",
    "\n",
    "    # Make target variable take values in {0,1} instead of {-1,1}, that is map {-1,1} to {0,1}\n",
    "    y_tr[y_tr == -1] = 0\n",
    "\n",
    "    # Add offset term to x_tr\n",
    "    x_tr = np.c_[np.ones(x_tr.shape[0]), x_tr]\n",
    "\n",
    "    return x_tr, y_tr, kept_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers (9 typically represents unknown/missing information => remove datapoints with these kind of numbers)\n",
    "# Standardize features ?\n",
    "# Are the classes equal? If not equilibrate them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_tr, y_tr, kept_features = clean_data(x_train, y_train, 0.2, 0.95, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109379, 52)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[:, kept_features].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, loss = implementations.reg_logistic_regression(y_tr, tx_tr, lambda_ = 0.05, initial_w = np.ones(tx_tr.shape[1]), max_iters = 510, gamma = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns with more than lim_col [%] of Nans\n",
    "lim_col = 0.2\n",
    "percentages = np.sum(np.isnan(x_train), axis = 0) / x_train.shape[0]\n",
    "x_tr = x_train[:, percentages < lim_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove datapoints (rows) with one or multiple Nans\n",
    "keep_idxs = (np.sum(np.isnan(x_tr), axis = 1)) == 0\n",
    "x_tr = x_tr[keep_idxs, :]\n",
    "y_tr = y_train[keep_idxs] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove features with 0 variance\n",
    "var = np.var(x_tr, axis = 0)\n",
    "x_tr = x_tr[:, var != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove highly correlated features\n",
    "lim_corr = 0.95\n",
    "corr_tri = np.triu(np.abs(np.corrcoef(x_tr, rowvar = False)), k = 1) # upper triangular correlation matrix (diagonal zeroed as well)\n",
    "max_corr = np.max(corr_tri, axis = 0)\n",
    "x_tr = x_tr[:, max_corr < lim_corr] # 118 features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove features that have very low correlation with target value\n",
    "lim_corr = 0.05\n",
    "corr_mat = np.abs(np.corrcoef(np.c_[y_tr, x_tr], rowvar = False))\n",
    "# First row of correlation matrix indicates correlation with target value vector y\n",
    "x_tr = x_tr[:, corr_mat[0, 1:] > lim_corr] # 52 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(x_tr, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_values = np.tile(np.max(x_tr, axis = 0), (x_tr.shape[0], 1))\n",
    "#np.sum(x_tr[0,:] == np.max(x_tr, axis = 0)) == 0\n",
    "np.sum(np.sum(x_tr == max_values, axis = 1) <= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
